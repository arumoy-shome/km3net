% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{Replacement for Hit Correlation Step} % top level followed by section, subsection

% ----------------------- contents from here ------------------------
% 
This chapter presents the replacement created using a Multi Layered
Perceptron (MLP) for the \textit{Hit Correlation Step} of the Karas
pipeline (see \ref{sec:karas-pipeline}). It is observed that a MLP is
able to identify causally related hits with a higher accuracy,
precision and recall compared to the Pattern Matrix Criterion. The
chapter begins by explaining how the data is created followed by its
visual examination. The training and testing procedure for the model
is explained next. The chapter concludes with discussions of the
experiment results and next steps.

\section{Data Preparation}
\label{sec:pm-data-prep}

A random sample was taken from the top 5 timeslices with the most
number of event hits for the creation of the pattern matrix dataset,
since these timeslices contain the highest number of event hits
compared to other timeslices. This is useful since the dataset is
highly skewed and using a timeslice with lesser number of event hits
will proliferate the skewed nature of the data in the pattern matrix
dataset once created. The model is required to classify related and
unrelated hits which can be done by observing the space and time
difference between the given points. Since this phenomenon is
consistent across the entire dataset, training using a sample does not
introduce any bias into the model.

% TODO find the mathematical term for the series, could be n^{2}-n!
Figure \ref{fig:pm-dataset} summarizes the pattern matrix dataset
creation process. With an input data of shape \texttt{(n, 4)}
(\texttt{n} rows and 4 columns representing the \texttt{x, y, z, and
  time}), an output data of shape \texttt{($\sum_{k=n-1}^{1}k$, 9)} is
obtained. A significant rise in the number of rows is observed since
each row (representing a single hit) is paired with the remaining
unique rows. The output dataset consists of 9 columns due to the
presence of \texttt{x, y, z and t} columns of two hits plus the
label column.

The label column is populated based on the values of the
\texttt{event\_id} column of the two hits. The row is assigned a label
of 1 if the two hits have the same event id, which signifies that they
originated from the same neutrino event and hence are causally related
to each other. If the event id of the two hits are not the same then
they are assigned a label of 0.

Better model performance was observed when the model was trained with
the difference between hits in time and space. As a result, the
pattern matrix was modified such that a dataset of shape
\texttt{$\sum_{k=n-1}^{1}k$, 5} was obtained. The fist 4 column being the
difference of the \texttt{x, y, z and t} columns and the last column
being the label.

\subsection{Preparation of Training Data}
\label{sec:pm-data-prep-train}

The main dataset is highly skewed, with the \textbf{majority class}
being hits from background noise and the \textbf{minority class} being
hits from neutrino events. Thus, the \textit{pattern matrix} dataset
is also skewed with the minority class being related hits and majority
class being unrelated hits. In binary classification, the majority
class is also referred to as the \textbf{negative class} (since it
usually has a label of 0) and the minority class is referred to as the
\textbf{positive class} (since usually has a label of 1). Henceforth
this alternative naming convention is used in this report.

Figure \ref{fig:pm-data-dist} shows the distribution of the two
classes in the pattern matrix dataset. As observed, a several
imbalance between the two classes exist. Training the model with such
a skewed dataset will result in a model that is biased to the majority
class. To combat this problem, the majority class is undersampled
\cite{CITEME} such that the number of examples for each class is the
same.

\subsection{Preparation of Testing Data}
\label{sec:pm-data-prep-test}

Whilst the training dataset contains equal number of examples for each
class, the testing dataset maintains it's skewed distribution since
this represents realistic data which the model will be required to
classify. Four variants of the testing dataset with varying level of
examples of related hits were created as listed below.

In practise, the pipeline will observe timeslices which contain no to
very few related hits, thus the performance of the model on test set
1 and 2 are of vital importance.

\begin{enumerate}
\item Test set containing no related hits
\item Test set containing less than 25 related hits
\item Test set containing less than 500 related hits
\item Test set containing less than 1500 related hits
\end{enumerate}

% TODO exploration of pattern matrix dataset
\section{Data Exploration and Visualization}

\section{Model Description}
\label{sec:pm-mpdel-desc}

The expectation of the model is to identify if two given points are
causally related to each other or not. As revealed through data
exploration in Chapter \ref{cha:data-exploration}, hits originating from
neutrino events occur close to each other in space and time. Thus, The
expectation from the model is to learn this phenomenon by training
over pairs of points and classify unseen data as related or unrelated.

% TODO add table to summarize the model params
Being a binary classification task, the \textit{Binary Cross Entropy
  Loss (BCELoss)} was selected as the loss function since it has been
established as the standard loss function for binary classification
tasks \cite{CITEME}. As the BCELoss function expects an input in the
range of $[0, 1]$, the \textit{Sigmoid} activation function was chosen
for the output layer. The \textit{ReLu} activation was chosen for the
hidden layers due to its XYZ properties as supported by many literate
\cite{CITME}. The model architecture consists of an input layer, two
hidden layers and an output layer. Figure \ref{fig:mlp-overview}
summarizes the model parameters and architecture. The network is fully
connected with 4 neurons in the input layer, 16 neurons in the first
hidden layer, 8 in the second hidden layer and finally 1 neuron in the
output layer. The Adam optimizer with a learning rate of 0.001 is used
to optimize the loss function.

The optimal value of all parameters stated above were identified
empirically. The number of epochs used to train the model varied per
experiment. This is because, this parameter is largely determined by
the dataset itself and the learning rate of the optimizer.

\section{Model Evaluation}
\label{sec:pm-model-eval}

The model is evaluated using several metrics which are regarded as the
standard set of metrics used by deep learning practitioners to
evaluate any machine learning model.

\begin{enumerate}
\item \textbf{Accuracy}. The accuracy is the ability of a model to
  classify unseen data correctly. Mathematically it can be defined as
  the number of correct predictions divided by the total number of
  examples in the test set.
\item \textbf{Loss Curve}. The loss curve is a line plot of the loss
  over the training epochs. A model with a good fit results in a loss
  curve which approaches 0 with time.
\end{enumerate}

\subsection{Additional Evaluation Metrics for Highly Skewed Data}
\label{sec:eval-metrics-skewed}

For highly skewed data, accuracy is not a good metric for evaluating
the model performance \cite{branco2015survey} thus the following
alternatives are also considered for the evaluation of the model.

\begin{enumerate}
\item \textbf{Recall} is the ability of the model to correctly
  identify the minority class. For this problem, the recall of the
  model is given precedence over its precision. This is because the
  model should be able to identify all instances of the positive class
  since this determines if the timeslice will ultimately be saved or
  not.
\item \textbf{Precision} is the ability of the model to not
  misclassify an instance of the negative class (ie. classify it as
  the positive class). Although this should also be high, it is often
  inversely proportional to recall.
\item \textbf{F1 score} is the harmonic mean of the precision and
  recall. The F1 score is a value between [0, 1] with a value close to
  1 indicating high precision and recall.
\item \textbf{F2 score} since recall is given precedence for this
  problem, the F2 score can be considered a better alternative to the
  F1 score as it gives higher importance to the recall through the
  $\beta$ parameter.
\item \textbf{Receiver Operating Characteristic (ROC) curve} is a plot
  of the false positive rate and the false negative rate across
  various probability thresholds. The area under the ROC curve (ROC
  AUC) is also considered.
\item \textbf{Precision-Recall (PR) Curve} can be considered a better
  alternative to the ROC curve since the ROC curve can be overly
  optimistic of the model's skill for skewed data. The Area under the
  PR curve (PR AUC) is also considered.
\item \textbf{Confusion Matrix} is used to visualize the true
  positive, true negative, false positive and false negative
  predictions of the model.
\end{enumerate}

\section{Discussion}
\label{sec:pm-disc}
% TODO discussion of results of best model

% ---------------------------------------------------------------------------
% ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------
